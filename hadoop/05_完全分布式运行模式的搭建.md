#### 准备:

> 1.准备三台客户机(关闭防火墙,静态ip,主机名称)  
> 2.安装jdk  
> 3.配置环境变量  
> 4.安装hadoop
> 5.配置环境变量
> 6.配置集群  
> 7.单点启动  
> 8.配置ssh  
> 9.群起并测试集群

#### 编写集群分发脚本:

> 1.`scp(secure copy)`安全拷贝
> ##### 2.scp定义:
> scp可以实现服务器与服务器之间的数据拷贝,(from server to server2)  
> 基本语法:   
> `scp -r $pdir/$fname $user@host:$pdir/$fname`  
> `命令 递归 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称  `
> #### 3.案例实操
> 前提:在hadoop102,hadoop103,hadoop104都已经创建好的`/opt/module`,`/opt/software` 两个目录,并且已经把这两个目录修改为了 atguigu:atguigu  
> $`sudo chown atguigu:atguigu -R /opt/module`  
> 在hadoop102上,将hadoop102中/opt/module/jkd1.8.0_212目录拷贝到hadoop103上

#### `rsync`远程同步工具:

> rsync主要用于备份和镜像,具有速度快,避免复制相同内容和支持符号链接的优点  
> `rsync`和`scp`的区别:用rsync做文件的复制要比scp的速度快,`rsync`只对差异文件做更新,scp是把所有文件都复制过去
> ##### 1.基本语法:
> `rsync -av $pdir/$fname $user@host:$pdir/$fname`  
> `命令 选项参数 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称`  
> 选项参数说明:

| 选项 | 功能 |
| --- | --- |
| -a  | 归档拷贝 |
| -v | 显示复制过程 |

> #### 2.实操案例:
> a.删除hadoop103中的 /opt/module/hadoop-3.1.3/wcinput:  
> `rsvync -av hadoop-3.1.3/atguigu@hadoop103:/opt/module/hadoop-3.1.3/`  
> 
> 


